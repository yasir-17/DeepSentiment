{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfc25ee5-60ed-4d8a-b3f1-d690148f041a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ccf8af-c485-4367-b773-ed7c29d0c230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob=0.3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional=True, dropout=dropout_prob)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 32)\n",
    "        self.fc2 = nn.Linear(32, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim * 2, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.layer_dim * 2, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.dropout(self.relu(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b0f716b-df84-412b-99ba-782d792fcd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_stock_data(df, ma_periods=[5, 10, 20, 50]):\n",
    "    data = df.copy()\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data.set_index('Date', inplace=True)\n",
    "    \n",
    "    for period in ma_periods:\n",
    "        data[f'MA_{period}'] = data['Adj Close'].rolling(window=period).mean()\n",
    "    \n",
    "    data['Price_Change'] = data['Adj Close'].pct_change()\n",
    "    data['Volume_Change'] = data['Volume'].pct_change()\n",
    "    \n",
    "    if 'sentiment' not in data.columns:\n",
    "        data['sentiment'] = 0.0\n",
    "        \n",
    "    selected_features = ['Adj Close', 'Volume', 'Price_Change', 'Volume_Change', 'sentiment'] + \\\n",
    "                       [f'MA_{period}' for period in ma_periods]\n",
    "    \n",
    "    processed_data = data[selected_features]\n",
    "    processed_data.dropna(inplace=True)\n",
    "    return processed_data\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length, 0])  # 0 index for Adj Close\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6e3ee4b-aae7-486c-8929-2bfd8e041fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Load and prepare data\n",
    "    df = pd.read_csv('processed_stock_data_aapl.csv')\n",
    "    processed_df = prepare_stock_data(df)\n",
    "    \n",
    "    # Split data into train and test (80-20 split)\n",
    "    train_size = int(0.8 * len(processed_df))\n",
    "    train_data = processed_df[:train_size]\n",
    "    test_data = processed_df[train_size:]\n",
    "    \n",
    "    # Save test data for later use\n",
    "    test_data.to_csv('test_data.csv')\n",
    "    \n",
    "    # Scale the training data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data)\n",
    "    \n",
    "    # Save scaler parameters\n",
    "    scaler_params = {\n",
    "        'data_min_': scaler.data_min_.tolist(),\n",
    "        'data_max_': scaler.data_max_.tolist(),\n",
    "        'data_range_': scaler.data_range_.tolist(),\n",
    "        'scale_': scaler.scale_.tolist(),\n",
    "        'min_': scaler.min_.tolist(),\n",
    "    }\n",
    "    with open('scaler_params.json', 'w') as f:\n",
    "        json.dump(scaler_params, f)\n",
    "    \n",
    "    # Create sequences\n",
    "    sequence_length = 20\n",
    "    X_train, y_train = create_sequences(scaled_train_data, sequence_length)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "    \n",
    "    # Create data loader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    input_dim = X_train.shape[2]\n",
    "    model = LSTMModel(input_dim=input_dim, hidden_dim=128, layer_dim=2, output_dim=1)\n",
    "    \n",
    "    # Training parameters\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 50\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'stock_prediction_model.pth')\n",
    "    \n",
    "    print(\"Training completed. Model and scaler parameters saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a00165a8-e0bb-4ee1-9e23-b1ffcb316757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(9, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_stock_prices(file, prediction_days):\n",
    "    try:\n",
    "        # Load scaler parameters\n",
    "        with open('scaler_params.json', 'r') as f:\n",
    "            scaler_params = json.load(f)\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.data_min_ = np.array(scaler_params['data_min_'])\n",
    "        scaler.data_max_ = np.array(scaler_params['data_max_'])\n",
    "        scaler.data_range_ = np.array(scaler_params['data_range_'])\n",
    "        scaler.scale_ = np.array(scaler_params['scale_'])\n",
    "        scaler.min_ = np.array(scaler_params['min_'])\n",
    "        \n",
    "        # Load and prepare test data\n",
    "        df = pd.read_csv(file.name)\n",
    "        processed_df = prepare_stock_data(df)\n",
    "        scaled_data = scaler.transform(processed_df)\n",
    "        \n",
    "        # Create sequences\n",
    "        sequence_length = 20\n",
    "        X, _ = create_sequences(scaled_data, sequence_length)\n",
    "        X = torch.FloatTensor(X)\n",
    "        \n",
    "        # Load the trained model\n",
    "        input_dim = X.shape[2]\n",
    "        model = LSTMModel(input_dim=input_dim, hidden_dim=128, layer_dim=2, output_dim=1)\n",
    "        model.load_state_dict(torch.load('stock_prediction_model.pth'))\n",
    "        \n",
    "        # Make predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            last_sequence = X[-2:]\n",
    "            predictions = []\n",
    "            \n",
    "            for _ in range(prediction_days):\n",
    "                pred = model(last_sequence).item()\n",
    "                predictions.append(pred)\n",
    "                \n",
    "                new_row = last_sequence[0, 1:].clone()\n",
    "                new_row = torch.cat([new_row, torch.tensor([[pred] + [0] * (input_dim-1)], dtype=torch.float32)])\n",
    "                last_sequence = new_row.unsqueeze(0)\n",
    "        \n",
    "        # Inverse transform predictions\n",
    "        predictions = np.array(predictions).reshape(-1, 1)\n",
    "        predictions = scaler.inverse_transform(np.hstack([predictions, np.zeros((len(predictions), input_dim-1))]))[: ,0]\n",
    "        \n",
    "        # Create dates for predictions\n",
    "        last_date = pd.to_datetime(df['Date'].iloc[-1])\n",
    "        future_dates = [(last_date + timedelta(days=x+1)) for x in range(prediction_days)]\n",
    "        \n",
    "        # Create plot\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Historical prices\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['Date'][-50:],\n",
    "            y=df['Adj Close'][-50:],\n",
    "            name='Historical Price',\n",
    "            line=dict(color='blue')\n",
    "        ))\n",
    "        \n",
    "        # Predictions\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=future_dates,\n",
    "            y=predictions,\n",
    "            name='Predicted Price',\n",
    "            line=dict(color='red', dash='dash')\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Stock Price Prediction',\n",
    "            xaxis_title='Date',\n",
    "            yaxis_title='Price',\n",
    "            hovermode='x unified'\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a77b384-32e6-45d6-8915-68bcb20375d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training model...\")\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b64d6-ccd8-435a-bdcf-2b992a1f0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "        fn=predict_stock_prices,\n",
    "        inputs=[\n",
    "            gr.File(label=\"Upload test data CSV file\"),\n",
    "            gr.Slider(minimum=1, maximum=30, value=7, step=1, label=\"Number of days to predict\")\n",
    "        ],\n",
    "        outputs=gr.Plot(),\n",
    "        title=\"Stock Price Prediction using LSTM\",\n",
    "        description=\"Upload a CSV file containing test data with columns: Date, Adj Close, Volume, and optionally sentiment. The model will predict future stock prices.\",\n",
    "        cache_examples=True\n",
    ")\n",
    "\n",
    "iface.launch(server_port=7865)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "hf-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
