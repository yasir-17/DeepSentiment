{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2c7ce85f-1355-4d70-b8d8-534d2cc24475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1b360307-b543-43a1-b33b-e09b02934f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "stock_directory = 'data/price/raw'\n",
    "stock_data = {}\n",
    "\n",
    "csv_files = [file for file in os.listdir(stock_directory) if file.endswith('.csv')]\n",
    "for file in csv_files:\n",
    "    symbol = file.split('.')[0]  # Extract stock symbol from filename\n",
    "    df = pd.read_csv(os.path.join(stock_directory, file))\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    stock_data[symbol] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e1fa6628-fcb5-4e93-b270-ac8a9499b097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>34.040001</td>\n",
       "      <td>34.130001</td>\n",
       "      <td>33.730000</td>\n",
       "      <td>33.799999</td>\n",
       "      <td>29.324499</td>\n",
       "      <td>14717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-05</td>\n",
       "      <td>33.840000</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>33.740002</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>29.281118</td>\n",
       "      <td>16121100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>34.950001</td>\n",
       "      <td>33.970001</td>\n",
       "      <td>34.840000</td>\n",
       "      <td>30.226799</td>\n",
       "      <td>32143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>34.959999</td>\n",
       "      <td>35.189999</td>\n",
       "      <td>34.740002</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>30.365608</td>\n",
       "      <td>26773900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>34.869999</td>\n",
       "      <td>34.939999</td>\n",
       "      <td>34.590000</td>\n",
       "      <td>34.590000</td>\n",
       "      <td>30.009895</td>\n",
       "      <td>19616700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>51.950001</td>\n",
       "      <td>52.020000</td>\n",
       "      <td>51.419998</td>\n",
       "      <td>51.630001</td>\n",
       "      <td>51.630001</td>\n",
       "      <td>12425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>51.209999</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>51.130001</td>\n",
       "      <td>51.419998</td>\n",
       "      <td>51.419998</td>\n",
       "      <td>10715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>51.459999</td>\n",
       "      <td>51.740002</td>\n",
       "      <td>51.200001</td>\n",
       "      <td>51.360001</td>\n",
       "      <td>51.360001</td>\n",
       "      <td>11427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.240002</td>\n",
       "      <td>50.869999</td>\n",
       "      <td>51.070000</td>\n",
       "      <td>51.070000</td>\n",
       "      <td>25231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>51.060001</td>\n",
       "      <td>51.490002</td>\n",
       "      <td>50.930000</td>\n",
       "      <td>50.970001</td>\n",
       "      <td>50.970001</td>\n",
       "      <td>16191900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Adj Close  \\\n",
       "0    2012-09-04  34.040001  34.130001  33.730000  33.799999  29.324499   \n",
       "1    2012-09-05  33.840000  34.009998  33.740002  33.750000  29.281118   \n",
       "2    2012-09-06  33.980000  34.950001  33.970001  34.840000  30.226799   \n",
       "3    2012-09-07  34.959999  35.189999  34.740002  35.000000  30.365608   \n",
       "4    2012-09-10  34.869999  34.939999  34.590000  34.590000  30.009895   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1253 2017-08-28  51.950001  52.020000  51.419998  51.630001  51.630001   \n",
       "1254 2017-08-29  51.209999  51.500000  51.130001  51.419998  51.419998   \n",
       "1255 2017-08-30  51.459999  51.740002  51.200001  51.360001  51.360001   \n",
       "1256 2017-08-31  51.000000  51.240002  50.869999  51.070000  51.070000   \n",
       "1257 2017-09-01  51.060001  51.490002  50.930000  50.970001  50.970001   \n",
       "\n",
       "        Volume  \n",
       "0     14717600  \n",
       "1     16121100  \n",
       "2     32143100  \n",
       "3     26773900  \n",
       "4     19616700  \n",
       "...        ...  \n",
       "1253  12425900  \n",
       "1254  10715500  \n",
       "1255  11427500  \n",
       "1256  25231100  \n",
       "1257  16191900  \n",
       "\n",
       "[1258 rows x 7 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data['WFC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ad4c6630-b0a5-4fa4-abcb-693e4ebd1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "tweet_directory = 'data/tweet/raw'\n",
    "tweets_data = {}\n",
    "tweet_threshold = 500\n",
    "\n",
    "for stock_folder in os.listdir(tweet_directory):\n",
    "    stock_path = os.path.join(tweet_directory, stock_folder)\n",
    "    if os.path.isdir(stock_path):\n",
    "        all_tweets = []\n",
    "        count = 0\n",
    "        for tweet_file in os.listdir(stock_path):\n",
    "            count += 1\n",
    "            file_path = os.path.join(stock_path, tweet_file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        tweet_json = json.loads(line.strip())\n",
    "                        tweet_data = {\n",
    "                            'Date': pd.to_datetime(tweet_json['created_at']),\n",
    "                            'Text': tweet_json['text'],\n",
    "                            'User': tweet_json['user']['screen_name'],\n",
    "                            'Followers': tweet_json['user']['followers_count'],\n",
    "                            'Friends': tweet_json['user']['friends_count']\n",
    "                        }\n",
    "                        all_tweets.append(tweet_data)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON in file {file_path}\")\n",
    "        # if len(all_tweets) >= tweet_threshold:\n",
    "        if count >= tweet_threshold:\n",
    "            tweets_data[stock_folder] = pd.DataFrame(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "32b53767-1545-43b3-b103-4d3267f249f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_data = {symbol: df for symbol, df in stock_data.items() if symbol in tweets_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "259e1c8a-8a99-4b75-86de-74af9538d71d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "051ee09e-1533-40a7-bd8f-05b6f7eabc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for stock, df in tweets_data.items():\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "    tweets_data[stock] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fcdd8127-511d-4018-b1e0-df513c640e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for stock, df in tweets_data.items():\n",
    "    grouped = df.groupby('Date').agg({\n",
    "        'Text': list,          \n",
    "        'User': list,          \n",
    "        'Followers': list,     \n",
    "        'Friends': list        \n",
    "    }).reset_index()\n",
    "\n",
    "    tweets_data[stock] = grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "052da9af-7588-4337-98d5-0d9cbafccec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of common dates: 373\n"
     ]
    }
   ],
   "source": [
    "stock_data['BA']['Date'] = pd.to_datetime(stock_data['BA']['Date'])\n",
    "tweets_data['BA']['Date'] = pd.to_datetime(tweets_data['BA']['Date'])\n",
    "\n",
    "common_dates = pd.Series(list(set(stock_data['BA']['Date']).intersection(set(tweets_data['BA']['Date']))))\n",
    "\n",
    "common_dates_count = len(common_dates)\n",
    "\n",
    "print(\"Count of common dates:\", common_dates_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "02284b46-0857-4198-94dd-a4bb238c3ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for stock in stock_data.keys():\n",
    "    if stock in tweets_data:\n",
    "        \n",
    "        stock_data[stock]['Date'] = pd.to_datetime(stock_data[stock]['Date'])\n",
    "        tweets_data[stock]['Date'] = pd.to_datetime(tweets_data[stock]['Date'])\n",
    "\n",
    "        merged_data = stock_data[stock].merge(tweets_data[stock], on='Date', how='left')\n",
    "        \n",
    "        stock_data[stock] = merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f5d4fde1-9b33-44a7-82fb-cd27374b55d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>137.250000</td>\n",
       "      <td>135.509995</td>\n",
       "      <td>136.669998</td>\n",
       "      <td>123.228493</td>\n",
       "      <td>3366700</td>\n",
       "      <td>[ARROM&amp;amp;¨%#@$BA http://t.co/2Osw4Xl9GF]</td>\n",
       "      <td>[bowsjauregui]</td>\n",
       "      <td>[1748]</td>\n",
       "      <td>[835]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>137.059998</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>137.050003</td>\n",
       "      <td>137.619995</td>\n",
       "      <td>124.085045</td>\n",
       "      <td>3177400</td>\n",
       "      <td>[$BA Jan. 3 Premarket Briefing: 10 Things You ...</td>\n",
       "      <td>[CordiaBranam]</td>\n",
       "      <td>[156]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>139.399994</td>\n",
       "      <td>139.759995</td>\n",
       "      <td>137.800003</td>\n",
       "      <td>138.410004</td>\n",
       "      <td>124.797371</td>\n",
       "      <td>4196500</td>\n",
       "      <td>[$BA [video] Why Would Zynga Take Bitcoin? htt...</td>\n",
       "      <td>[MonteMose, CordiaBranam, sfef84, stockwire24]</td>\n",
       "      <td>[3, 153, 225, 931]</td>\n",
       "      <td>[0, 0, 201, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>138.580002</td>\n",
       "      <td>141.100006</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>140.509995</td>\n",
       "      <td>126.690819</td>\n",
       "      <td>4238500</td>\n",
       "      <td>[The Boeing Company (BA): Boeing logs record n...</td>\n",
       "      <td>[stockwire24, TheStockHerald, stocknews77]</td>\n",
       "      <td>[932, 9, 207]</td>\n",
       "      <td>[1, 0, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>140.690002</td>\n",
       "      <td>141.399994</td>\n",
       "      <td>139.360001</td>\n",
       "      <td>140.820007</td>\n",
       "      <td>126.970329</td>\n",
       "      <td>4236100</td>\n",
       "      <td>[The Boeing Company : Boeing stays top planema...</td>\n",
       "      <td>[stockwire24]</td>\n",
       "      <td>[935]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>135.139999</td>\n",
       "      <td>136.100006</td>\n",
       "      <td>134.779999</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>129.024033</td>\n",
       "      <td>4989000</td>\n",
       "      <td>[RSALAZAR: OTC $TPAC with NYSE $BA https://t.c...</td>\n",
       "      <td>[WallStreetPenni]</td>\n",
       "      <td>[11017]</td>\n",
       "      <td>[2328]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2016-03-23</td>\n",
       "      <td>134.990005</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>132.740005</td>\n",
       "      <td>132.860001</td>\n",
       "      <td>126.865990</td>\n",
       "      <td>4361200</td>\n",
       "      <td>[First Citizens Bank &amp;amp; Trust Co. Sells 7,0...</td>\n",
       "      <td>[AmericanBanking]</td>\n",
       "      <td>[6044]</td>\n",
       "      <td>[2296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>129.830002</td>\n",
       "      <td>130.929993</td>\n",
       "      <td>128.179993</td>\n",
       "      <td>130.880005</td>\n",
       "      <td>124.975327</td>\n",
       "      <td>4910200</td>\n",
       "      <td>[$BA $AAMRQ:\\n\\nEgypt Hijacking Without Passen...</td>\n",
       "      <td>[ProVesting, _aerospace, _aerospace, _aerospac...</td>\n",
       "      <td>[730, 40, 40, 39, 730, 40, 40]</td>\n",
       "      <td>[6, 3, 3, 3, 6, 28, 28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>131.479996</td>\n",
       "      <td>132.729996</td>\n",
       "      <td>128.020004</td>\n",
       "      <td>128.580002</td>\n",
       "      <td>122.779083</td>\n",
       "      <td>5949000</td>\n",
       "      <td>[Dow Analysts Forecast 44.21% More Gain With I...</td>\n",
       "      <td>[SA_IncomeInvest, InvestorPlace, KanikaSikka, ...</td>\n",
       "      <td>[1819, 5986, 529, 529, 2, 9, 9, 200, 200]</td>\n",
       "      <td>[31, 657, 874, 874, 22, 1, 1, 27, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>128.089996</td>\n",
       "      <td>128.380005</td>\n",
       "      <td>125.250000</td>\n",
       "      <td>126.940002</td>\n",
       "      <td>121.213066</td>\n",
       "      <td>8758300</td>\n",
       "      <td>[RT @SeekingAlpha: A Boring Or Banging Year Ah...</td>\n",
       "      <td>[amrokadri]</td>\n",
       "      <td>[1099]</td>\n",
       "      <td>[685]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "333 2014-01-02  136.009995  137.250000  135.509995  136.669998  123.228493   \n",
       "334 2014-01-03  137.059998  138.500000  137.050003  137.619995  124.085045   \n",
       "335 2014-01-06  139.399994  139.759995  137.800003  138.410004  124.797371   \n",
       "336 2014-01-07  138.580002  141.100006  138.500000  140.509995  126.690819   \n",
       "337 2014-01-08  140.690002  141.399994  139.360001  140.820007  126.970329   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "891 2016-03-22  135.139999  136.100006  134.779999  135.119995  129.024033   \n",
       "892 2016-03-23  134.990005  135.000000  132.740005  132.860001  126.865990   \n",
       "895 2016-03-29  129.830002  130.929993  128.179993  130.880005  124.975327   \n",
       "896 2016-03-30  131.479996  132.729996  128.020004  128.580002  122.779083   \n",
       "897 2016-03-31  128.089996  128.380005  125.250000  126.940002  121.213066   \n",
       "\n",
       "      Volume                                               Text  \\\n",
       "333  3366700         [ARROM&amp;¨%#@$BA http://t.co/2Osw4Xl9GF]   \n",
       "334  3177400  [$BA Jan. 3 Premarket Briefing: 10 Things You ...   \n",
       "335  4196500  [$BA [video] Why Would Zynga Take Bitcoin? htt...   \n",
       "336  4238500  [The Boeing Company (BA): Boeing logs record n...   \n",
       "337  4236100  [The Boeing Company : Boeing stays top planema...   \n",
       "..       ...                                                ...   \n",
       "891  4989000  [RSALAZAR: OTC $TPAC with NYSE $BA https://t.c...   \n",
       "892  4361200  [First Citizens Bank &amp; Trust Co. Sells 7,0...   \n",
       "895  4910200  [$BA $AAMRQ:\\n\\nEgypt Hijacking Without Passen...   \n",
       "896  5949000  [Dow Analysts Forecast 44.21% More Gain With I...   \n",
       "897  8758300  [RT @SeekingAlpha: A Boring Or Banging Year Ah...   \n",
       "\n",
       "                                                  User  \\\n",
       "333                                     [bowsjauregui]   \n",
       "334                                     [CordiaBranam]   \n",
       "335     [MonteMose, CordiaBranam, sfef84, stockwire24]   \n",
       "336         [stockwire24, TheStockHerald, stocknews77]   \n",
       "337                                      [stockwire24]   \n",
       "..                                                 ...   \n",
       "891                                  [WallStreetPenni]   \n",
       "892                                  [AmericanBanking]   \n",
       "895  [ProVesting, _aerospace, _aerospace, _aerospac...   \n",
       "896  [SA_IncomeInvest, InvestorPlace, KanikaSikka, ...   \n",
       "897                                        [amrokadri]   \n",
       "\n",
       "                                     Followers  \\\n",
       "333                                     [1748]   \n",
       "334                                      [156]   \n",
       "335                         [3, 153, 225, 931]   \n",
       "336                              [932, 9, 207]   \n",
       "337                                      [935]   \n",
       "..                                         ...   \n",
       "891                                    [11017]   \n",
       "892                                     [6044]   \n",
       "895             [730, 40, 40, 39, 730, 40, 40]   \n",
       "896  [1819, 5986, 529, 529, 2, 9, 9, 200, 200]   \n",
       "897                                     [1099]   \n",
       "\n",
       "                                   Friends  \n",
       "333                                  [835]  \n",
       "334                                    [0]  \n",
       "335                         [0, 0, 201, 1]  \n",
       "336                              [1, 0, 6]  \n",
       "337                                    [1]  \n",
       "..                                     ...  \n",
       "891                                 [2328]  \n",
       "892                                 [2296]  \n",
       "895                [6, 3, 3, 3, 6, 28, 28]  \n",
       "896  [31, 657, 874, 874, 22, 1, 1, 27, 27]  \n",
       "897                                  [685]  \n",
       "\n",
       "[373 rows x 11 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = stock_data['BA'][stock_data['BA']['Text'].notna()]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fcaac16a-38e4-470a-9da8-5837b908e374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert stock data 'Date' index to datetime if necessary\n",
    "for stock, df in stock_data.items():\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    stock_data[stock] = df\n",
    "\n",
    "# Convert tweet data 'Date' column to datetime\n",
    "for stock, df in tweets_data.items():\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.date  # Ensure it's just the date part\n",
    "    tweets_data[stock] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05173f62-742e-4414-b635-5c8912cfc46f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on datetime64[ns] and object columns for key 'Date'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stock \u001b[38;5;129;01min\u001b[39;00m tweets_data:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Reset index of stock data to merge on 'Date'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     stock_df \u001b[38;5;241m=\u001b[39m stock_data[stock]\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m----> 5\u001b[0m     merged_data \u001b[38;5;241m=\u001b[39m \u001b[43mstock_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweets_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstock\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Fill missing values for days without tweets with empty lists or appropriate defaults\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     merged_data\u001b[38;5;241m.\u001b[39mfillna({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFollowers\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFriends\u001b[39m\u001b[38;5;124m'\u001b[39m: []}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/blue/yonghui.wu/y.khan/conda/envs/hf-llm/lib/python3.10/site-packages/pandas/core/frame.py:10490\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10471\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10472\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10486\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10487\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10488\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10491\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10500\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/yonghui.wu/y.khan/conda/envs/hf-llm/lib/python3.10/site-packages/pandas/core/reshape/merge.py:169\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    155\u001b[0m         left_df,\n\u001b[1;32m    156\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/blue/yonghui.wu/y.khan/conda/envs/hf-llm/lib/python3.10/site-packages/pandas/core/reshape/merge.py:804\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 804\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/blue/yonghui.wu/y.khan/conda/envs/hf-llm/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1483\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m-> 1483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on datetime64[ns] and object columns for key 'Date'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "for stock in stock_data.keys():\n",
    "    if stock in tweets_data:\n",
    "        # Reset index of stock data to merge on 'Date'\n",
    "        stock_df = stock_data[stock].reset_index()\n",
    "        merged_data = stock_df.merge(tweets_data[stock], on='Date', how='left')\n",
    "\n",
    "        # Fill missing values for days without tweets with empty lists or appropriate defaults\n",
    "        merged_data.fillna({'Text': [], 'User': [], 'Followers': [], 'Friends': []}, inplace=True)\n",
    "        \n",
    "        # Set Date back as index if needed\n",
    "        merged_data.set_index('Date', inplace=True)\n",
    "        \n",
    "        # Update the stock data dictionary with the merged DataFrame\n",
    "        stock_data[stock] = merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4fc0f-de17-469f-9f25-4c3625754f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "hf-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
